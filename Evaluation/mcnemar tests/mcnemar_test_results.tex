\begin{table}
\caption{McNemar's Test: Fine-tuned XLM-RoBERTa vs Zero-Shot Baseline (α=0.05)}
\label{tab:mcnemar_finetuned_vs_baseline}
\begin{tabular}{llrrrll}
\toprule
Fine-tuned Model & Language & FT Accuracy & Baseline Accuracy & Improvement & P-value & Significant (α=0.05) \\
\midrule
XLM-R-Multilingual & Arabic & 0.843263 & 0.521998 & 0.321265 & $<0.01$ & Yes \\
XLM-R-Arabic & Arabic & 0.709899 & 0.521998 & 0.187901 & $<0.01$ & Yes \\
XLM-R-English & Arabic & 0.654445 & 0.521998 & 0.132447 & $<0.01$ & Yes \\
XLM-R-Multilingual & English & 0.846013 & 0.497709 & 0.348304 & $<0.01$ & Yes \\
XLM-R-Arabic & English & 0.675527 & 0.497709 & 0.177819 & $<0.01$ & Yes \\
XLM-R-English & English & 0.717690 & 0.497709 & 0.219982 & $<0.01$ & Yes \\
\bottomrule
\end{tabular}
\end{table}
